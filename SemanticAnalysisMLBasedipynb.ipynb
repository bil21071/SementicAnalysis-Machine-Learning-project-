{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjSIOB_f6EE0",
        "outputId": "417030ac-7bda-4214-eb36-7b829c4d0f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-02 15:32:17--  https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz\n",
            "Resolving www.cs.jhu.edu (www.cs.jhu.edu)... 128.220.13.64\n",
            "Connecting to www.cs.jhu.edu (www.cs.jhu.edu)|128.220.13.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30586147 (29M) [application/x-gzip]\n",
            "Saving to: ‘domain_sentiment_data.tar.gz’\n",
            "\n",
            "domain_sentiment_da 100%[===================>]  29.17M  8.01MB/s    in 3.6s    \n",
            "\n",
            "2024-12-02 15:32:22 (8.01 MB/s) - ‘domain_sentiment_data.tar.gz’ saved [30586147/30586147]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz\"\n",
        "! tar -xzf \"/content/domain_sentiment_data.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6rwPQTs6rBO",
        "outputId": "5c5193d9-9855-4ea1-a45f-f04a744736d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aud0DYNK7Y1w"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def clean_sentence(sentence: str) -> list:\n",
        "  # Remove the review tag\n",
        "  tags = re.compile(\"(|<\\/review_text>)\")\n",
        "  sentence = re.sub(tags, '', sentence)\n",
        "\n",
        "  # lower case\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  # Remove emails and urls\n",
        "  email_urls = re.compile(\"(\\bhttp.+? | \\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b)\")\n",
        "  sentence = re.sub(email_urls, '', sentence)\n",
        "\n",
        "  # Some used '@' to hide offensive words (bla -> bl@)\n",
        "  ats = re.compile('@')\n",
        "  sentence = re.sub(ats, 'a', sentence)\n",
        "\n",
        "  # Remove Punctuation\n",
        "  # punc = re.compile(\"[!\\\"\\#$\\%\\&\\'\\*\\+,\\-\\.\\/\\:;<=>\\?\n",
        "  punc = re.compile(\"[^\\w\\s(\\w+\\-\\w+)]\")\n",
        "  sentence = re.sub(punc, '', sentence)\n",
        "\n",
        "  # Remove stopwords and tokenize\n",
        "  # sentence = sentence.split(sep=' ')\n",
        "  sentence = word_tokenize(sentence)\n",
        "  sentence = [word for word in sentence if not word in stopwords.words()]\n",
        "\n",
        "  # Stemming (Returning to root)\n",
        "  # stemmer = PorterStemmer()\n",
        "  # sentence = [stemmer.stem(word) for word in sentence]\n",
        "\n",
        "\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHpyaoN87y9U",
        "outputId": "28a22973-7dcd-4e77-ada0-84e6ff3decd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Train Data\n",
            "Reading 1000 Negative reviews from books\n",
            "Reading 1000 Positive reviews from books\n",
            "Reading 1000 Negative reviews from dvd\n",
            "Reading 1000 Positive reviews from dvd\n",
            "Reading 1000 Negative reviews from electronics\n",
            "Reading 1000 Positive reviews from electronics\n",
            "Reading Test Data\n",
            "Reading 1000 Negative reviews from kitchen_&_housewares\n",
            "Reading 1000 Positive reviews from kitchen_&_housewares\n"
          ]
        }
      ],
      "source": [
        "# Read files\n",
        "path = \"/content/sorted_data_acl/\"\n",
        "regex_review = re.compile(\".+?<\\/review_text>\", flags=re.DOTALL)\n",
        "\n",
        "# Training Data\n",
        "folders = [\"books\",\"dvd\",\"electronics\"]\n",
        "x_train = list()\n",
        "y_train = list()\n",
        "print('Reading Train Data')\n",
        "for folder in folders:\n",
        "  temp = open(path+folder+\"/negative.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Negative reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_train.append(clean_sentence(sentence))\n",
        "    y_train.append(0)\n",
        "\n",
        "\n",
        "  temp = open(path+folder+\"/positive.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Positive reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_train.append(clean_sentence(sentence))\n",
        "    y_train.append(1)\n",
        "\n",
        "\n",
        "\n",
        "# Test data\n",
        "folders = [\"kitchen_&_housewares\"]\n",
        "x_test = list()\n",
        "y_test = list()\n",
        "print('Reading Test Data')\n",
        "for folder in folders:\n",
        "  temp = open(path+folder+\"/negative.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Negative reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_test.append(clean_sentence(sentence))\n",
        "    y_test.append(0)\n",
        "\n",
        "\n",
        "  temp = open(path+folder+\"/positive.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Positive reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_test.append(clean_sentence(sentence))\n",
        "    y_test.append(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jg_T9AKS8q_4"
      },
      "outputs": [],
      "source": [
        "temp_file = open('x_train','wb')\n",
        "save_x_train = dump(x_train, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('y_train','wb')\n",
        "save_y_train = dump(y_train, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('x_test','wb')\n",
        "save_x_test = dump(x_test, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('y_test','wb')\n",
        "save_y_test = dump(y_test, temp_file)\n",
        "temp_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "71kaAu1z7UnO",
        "outputId": "69617e5d-68c8-4a60-cee6-77052555881e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max size: 1728\n",
            "Min size: 43\n",
            "Top 10 sizes: [535, 540, 540, 544, 551, 575, 589, 602, 629, 633, 639, 639, 644, 647, 662, 677, 686, 754, 1083, 1728]\n",
            "From  0.0 to 20.0 : 0.0\n",
            "From  20.0 to 40.0 : 0.0\n",
            "From  40.0 to 60.0 : 651.0\n",
            "From  60.0 to 80.0 : 1495.0\n",
            "From  80.0 to 100.0 : 1334.0\n",
            "From  100.0 to 120.0 : 736.0\n",
            "From  120.0 to 140.0 : 509.0\n",
            "From  140.0 to 160.0 : 320.0\n",
            "From  160.0 to 180.0 : 218.0\n",
            "From  180.0 to 200.0 : 157.0\n",
            "From  200.0 to 300.0 : 407.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "lengths = [len(sentence) for sentence in x_train]\n",
        "lengths.sort()\n",
        "print(\"Max size:\", max(lengths))\n",
        "print(\"Min size:\", min(lengths))\n",
        "print(\"Top 10 sizes:\",lengths[-20:])\n",
        "counts,bins,_ = plt.hist(lengths,bins=[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 300, 2000])\n",
        "for i in range(len(counts)-1):\n",
        "  print('From ',bins[i],'to',bins[i+1],':',counts[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for sentence in x_train:\n",
        "  for word in sentence:\n",
        "    vocab.add(word)\n",
        "\n",
        "vocab.add('') # for dummy words, to avoid adding a word that has a meaning\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "\n",
        "# Make a mapping betwween words and their IDs\n",
        "word2id = {word:id for  id, word in enumerate(vocab)}\n",
        "id2word = {id:word for  id, word in enumerate(vocab)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYZTaxVHkQ5i",
        "outputId": "249a6773-2cd9-4b1e-936e-a3abc538810d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 82841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_sentence(old_sentence):\n",
        "  encoded_sentence = []\n",
        "  dummy = word2id['']\n",
        "  for word in old_sentence:\n",
        "    try:\n",
        "      encoded_sentence.append(word2id[word])\n",
        "    except KeyError:\n",
        "      encoded_sentence.append(dummy) # the none char\n",
        "\n",
        "  return encoded_sentence\n",
        "\n",
        "\n",
        "# Encoding train sentences\n",
        "x_train_encoded = []\n",
        "for sentence in x_train:\n",
        "  x_train_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "# Encoding test sentences\n",
        "x_test_encoded = []\n",
        "for sentence in x_test:\n",
        "  x_test_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "print(\"Len train:\", len(x_train_encoded))\n",
        "print(\"Len test:\", len(x_test_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2rADiXBkdy2",
        "outputId": "01568fb1-c2e7-4d36-b801-443108a5d699"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len train: 6000\n",
            "Len test: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 125\n",
        "dummy = word2id['']\n",
        "# Padding train sentences\n",
        "x_train_padded = pad_sequences(x_train_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Train shape: \",x_train_padded.shape)\n",
        "\n",
        "# Padding test sentences\n",
        "x_test_padded = pad_sequences(x_test_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Test shape: \", x_test_padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcCoRbUvkgPi",
        "outputId": "ba27f0d6-1954-4a4c-8df1-cb508f03dd01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape:  (6000, 125)\n",
            "Test shape:  (2000, 125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)\n",
        "temp, = y_train.shape\n",
        "y_train = y_train.reshape((temp,1))\n",
        "y_train.shape\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "temp, = y_test.shape\n",
        "y_test = y_test.reshape((temp,1))\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et-oFk_uknCR",
        "outputId": "6c9ddeac-b637-4fce-9403-82b37dc4561b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = api.load('glove-twitter-200')\n",
        "w2v.most_similar(\"mahmoud\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFp3jPbMksVW",
        "outputId": "93e3c287-76a7-43f2-8675-e2cc0012bf3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mohamed', 0.71284019947052),\n",
              " ('mostafa', 0.689501166343689),\n",
              " ('ahmed', 0.6817302703857422),\n",
              " ('mohey', 0.6513986587524414),\n",
              " ('ahmadinejad', 0.6093316674232483),\n",
              " ('mohammed', 0.5743428468704224),\n",
              " ('youssef', 0.5647962689399719),\n",
              " ('morsi', 0.5544598698616028),\n",
              " ('hassan', 0.554221510887146),\n",
              " ('fouad', 0.5403571724891663)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(vocab)\n",
        "embed_size, = w2v['mahmoud'].shape\n",
        "embedding_matrix = np.zeros(shape=(num_words, embed_size))\n",
        "\n",
        "for word, id in word2id.items():\n",
        "  try:\n",
        "    embedding_matrix[id] = w2v[word]\n",
        "  except KeyError:\n",
        "    embedding_matrix[id] = np.zeros(embed_size)\n",
        "\n",
        "embedding_matrix.shape\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vSvak_cpTyy",
        "outputId": "5b0da918-209b-43ce-88db-d5d953eec43f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82841, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(vocab)\n",
        "embed_size, = w2v['mahmoud'].shape\n",
        "embedding_matrix = np.zeros(shape=(num_words, embed_size))\n",
        "\n",
        "for word, id in word2id.items():\n",
        "  try:\n",
        "    embedding_matrix[id] = w2v[word]\n",
        "  except KeyError:\n",
        "    embedding_matrix[id] = np.zeros(embed_size)\n",
        "\n",
        "embedding_matrix.shape\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n1CvOMKphN3",
        "outputId": "c897fe2f-df16-4823-e0f7-bad6788df9b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82841, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential(name='Rating')\n",
        "\n",
        "lstm_model.add(Input(shape=(MAX_SEQ_LEN,), dtype='int32'))\n",
        "lstm_model.add(Embedding(input_dim = len(vocab),            # Vocabulary Size (number of unique words for training)\n",
        "                        output_dim = embed_size,            # Length of the vector for each word (embedding dimension)\n",
        "                        input_length = MAX_SEQ_LEN,         # Maximum length of a sequence\n",
        "                        weights = [embedding_matrix],       # Send the needed glove-twitter-200 Weights\n",
        "                        trainable = False))\n",
        "\n",
        "lstm_model.add(LSTM(units = 30,\n",
        "                    return_sequences=True,\n",
        "                    # dropout=0.5,\n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(LSTM(units = 30,\n",
        "                    # return_sequences=True,\n",
        "                    # dropout=0.5,\n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999),\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "lstm_model.summary()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "OrsrL18Pp269",
        "outputId": "8d849d59-6418-46f8-a49d-67371d21aa43"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Rating\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Rating\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │      \u001b[38;5;34m16,568,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │          \u001b[38;5;34m27,720\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m7,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,568,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,720</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,603,271\u001b[0m (63.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,603,271</span> (63.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,071\u001b[0m (137.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,071</span> (137.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m16,568,200\u001b[0m (63.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,568,200</span> (63.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = shuffle(x_train_padded, y_train, random_state=42)"
      ],
      "metadata": {
        "id": "4e2VzJ0psDYt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save('lstm_w_770.h5',save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1LQqdkEsKiC",
        "outputId": "1657da0e-9173-44d9-e970-0d5412545f68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(train_data,\n",
        "               train_labels,\n",
        "               validation_split=0.20,\n",
        "               batch_size = 50,\n",
        "               epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px1NoHtNsZpM",
        "outputId": "d60011ad-937a-4122-e343-2fbd55074220"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - accuracy: 0.5049 - loss: 0.6946 - val_accuracy: 0.5108 - val_loss: 0.6924\n",
            "Epoch 2/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.5156 - loss: 0.6922 - val_accuracy: 0.5208 - val_loss: 0.6915\n",
            "Epoch 3/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5342 - loss: 0.6907 - val_accuracy: 0.5208 - val_loss: 0.6905\n",
            "Epoch 4/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - accuracy: 0.5414 - loss: 0.6890 - val_accuracy: 0.5267 - val_loss: 0.6885\n",
            "Epoch 5/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.5649 - loss: 0.6848 - val_accuracy: 0.5483 - val_loss: 0.6833\n",
            "Epoch 6/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5626 - loss: 0.6747 - val_accuracy: 0.6258 - val_loss: 0.6471\n",
            "Epoch 7/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.6710 - loss: 0.6189 - val_accuracy: 0.6650 - val_loss: 0.6179\n",
            "Epoch 8/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.7008 - loss: 0.5861 - val_accuracy: 0.7217 - val_loss: 0.5798\n",
            "Epoch 9/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 115ms/step - accuracy: 0.7346 - loss: 0.5642 - val_accuracy: 0.7283 - val_loss: 0.5675\n",
            "Epoch 10/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.7495 - loss: 0.5416 - val_accuracy: 0.7342 - val_loss: 0.5566\n",
            "Epoch 11/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.7558 - loss: 0.5324 - val_accuracy: 0.7350 - val_loss: 0.5651\n",
            "Epoch 12/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.7667 - loss: 0.5209 - val_accuracy: 0.7392 - val_loss: 0.5457\n",
            "Epoch 13/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.7773 - loss: 0.5013 - val_accuracy: 0.7567 - val_loss: 0.5347\n",
            "Epoch 14/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - accuracy: 0.7690 - loss: 0.5127 - val_accuracy: 0.7583 - val_loss: 0.5323\n",
            "Epoch 15/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 109ms/step - accuracy: 0.7902 - loss: 0.4820 - val_accuracy: 0.7592 - val_loss: 0.5254\n",
            "Epoch 16/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.7928 - loss: 0.4792 - val_accuracy: 0.7533 - val_loss: 0.5229\n",
            "Epoch 17/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.7917 - loss: 0.4751 - val_accuracy: 0.7567 - val_loss: 0.5254\n",
            "Epoch 18/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.8020 - loss: 0.4664 - val_accuracy: 0.7667 - val_loss: 0.5168\n",
            "Epoch 19/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 93ms/step - accuracy: 0.8072 - loss: 0.4588 - val_accuracy: 0.7642 - val_loss: 0.5142\n",
            "Epoch 20/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.7978 - loss: 0.4701 - val_accuracy: 0.7633 - val_loss: 0.5181\n",
            "Epoch 21/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.8124 - loss: 0.4449 - val_accuracy: 0.7658 - val_loss: 0.5124\n",
            "Epoch 22/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 123ms/step - accuracy: 0.8198 - loss: 0.4407 - val_accuracy: 0.7758 - val_loss: 0.5007\n",
            "Epoch 23/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 108ms/step - accuracy: 0.8285 - loss: 0.4254 - val_accuracy: 0.7742 - val_loss: 0.4976\n",
            "Epoch 24/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 109ms/step - accuracy: 0.8286 - loss: 0.4255 - val_accuracy: 0.7675 - val_loss: 0.4984\n",
            "Epoch 25/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 97ms/step - accuracy: 0.8314 - loss: 0.4200 - val_accuracy: 0.7633 - val_loss: 0.5019\n",
            "Epoch 26/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - accuracy: 0.8285 - loss: 0.4243 - val_accuracy: 0.7792 - val_loss: 0.4949\n",
            "Epoch 27/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8309 - loss: 0.4147 - val_accuracy: 0.7642 - val_loss: 0.5075\n",
            "Epoch 28/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - accuracy: 0.8360 - loss: 0.3987 - val_accuracy: 0.7800 - val_loss: 0.4939\n",
            "Epoch 29/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.8411 - loss: 0.4061 - val_accuracy: 0.7733 - val_loss: 0.4989\n",
            "Epoch 30/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.8492 - loss: 0.3855 - val_accuracy: 0.7825 - val_loss: 0.4972\n",
            "Epoch 31/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.8537 - loss: 0.3810 - val_accuracy: 0.7850 - val_loss: 0.4913\n",
            "Epoch 32/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 92ms/step - accuracy: 0.8498 - loss: 0.3906 - val_accuracy: 0.7733 - val_loss: 0.5163\n",
            "Epoch 33/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - accuracy: 0.8557 - loss: 0.3844 - val_accuracy: 0.7833 - val_loss: 0.4993\n",
            "Epoch 34/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.8640 - loss: 0.3710 - val_accuracy: 0.7767 - val_loss: 0.5006\n",
            "Epoch 35/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - accuracy: 0.8636 - loss: 0.3614 - val_accuracy: 0.7842 - val_loss: 0.4908\n",
            "Epoch 36/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.8623 - loss: 0.3711 - val_accuracy: 0.7783 - val_loss: 0.4914\n",
            "Epoch 37/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.8663 - loss: 0.3552 - val_accuracy: 0.7875 - val_loss: 0.5004\n",
            "Epoch 38/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8752 - loss: 0.3448 - val_accuracy: 0.7850 - val_loss: 0.4975\n",
            "Epoch 39/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.8746 - loss: 0.3544 - val_accuracy: 0.7800 - val_loss: 0.5133\n",
            "Epoch 40/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - accuracy: 0.8813 - loss: 0.3330 - val_accuracy: 0.7825 - val_loss: 0.5022\n",
            "Epoch 41/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8774 - loss: 0.3406 - val_accuracy: 0.7908 - val_loss: 0.4935\n",
            "Epoch 42/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.8776 - loss: 0.3406 - val_accuracy: 0.7867 - val_loss: 0.5019\n",
            "Epoch 43/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8846 - loss: 0.3343 - val_accuracy: 0.7775 - val_loss: 0.5099\n",
            "Epoch 44/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 112ms/step - accuracy: 0.8788 - loss: 0.3318 - val_accuracy: 0.7858 - val_loss: 0.5156\n",
            "Epoch 45/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.8858 - loss: 0.3178 - val_accuracy: 0.7567 - val_loss: 0.5694\n",
            "Epoch 46/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 96ms/step - accuracy: 0.8637 - loss: 0.3589 - val_accuracy: 0.7833 - val_loss: 0.5102\n",
            "Epoch 47/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.8984 - loss: 0.3024 - val_accuracy: 0.7867 - val_loss: 0.5390\n",
            "Epoch 48/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - accuracy: 0.8960 - loss: 0.3005 - val_accuracy: 0.7800 - val_loss: 0.5186\n",
            "Epoch 49/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.8956 - loss: 0.3066 - val_accuracy: 0.7842 - val_loss: 0.5294\n",
            "Epoch 50/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.8986 - loss: 0.2983 - val_accuracy: 0.7933 - val_loss: 0.5153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e446f048850>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l, a = lstm_model.evaluate(x_test_padded, y_test)\n",
        "print(\"Test accuracy:\", round(a*100,2),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s5iw0F04uBl",
        "outputId": "92dcb064-afc1-4c68-fe87-09ef86a60379"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7659 - loss: 0.5302\n",
            "Test accuracy: 79.45 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_predict(sentence:str):\n",
        "  sentence = clean_sentence(sentence)\n",
        "  # Encode sentence\n",
        "  ready_sentence = encode_sentence(sentence)\n",
        "  # Padding sentence\n",
        "  ready_sentence = pad_sequences(sequences = [ready_sentence],\n",
        "                                 maxlen=MAX_SEQ_LEN,\n",
        "                                 dtype='int32',\n",
        "                                 padding='post',\n",
        "                                 truncating='post',\n",
        "                                 value = dummy)\n",
        "\n",
        "  # Predict\n",
        "  prediction = round(lstm_model.predict(ready_sentence)[0][0])\n",
        "  if prediction==0:\n",
        "    print(\"Negative Review\")\n",
        "  elif prediction==1:\n",
        "    print(\"Positive Review\")\n",
        "  else:\n",
        "    print('Error')\n",
        ""
      ],
      "metadata": {
        "id": "zV-OAOEv40Xi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_predict(\"I really recommend this book\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfEyR6eH47A6",
        "outputId": "088b4212-ae44-46cb-ed41-db8a635ae317"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
            "Positive Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_predict(\"I don't know what the hell did i just read, the book is full nonsense\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDECaesQ5C84",
        "outputId": "72baef01-f892-4a05-c8c0-64ecb4144059"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Negative Review\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}